# ğŸ¤– Projet utilisant le modÃ¨le Gemma 3 (270M)

Ce projet utilise le modÃ¨le **[Gemma 3 (270M)](https://ollama.com/library/gemma3:270m)** via [**Ollama**](https://ollama.com/).  
Ce modÃ¨le est une petite version de la famille **Gemma 3**, optimisÃ©e pour tourner localement sur des machines modestes tout en offrant dâ€™excellentes performances pour le traitement de texte.

---

## ğŸš€ Installation

### 1. Installer Ollama
TÃ©lÃ©charge et installe **Ollama** depuis le site officiel :  
ğŸ‘‰ [https://ollama.com/download](https://ollama.com/download)

### 2. TÃ©lÃ©charger le modÃ¨le Gemma 3 (270M)
Une fois Ollama installÃ©, exÃ©cute cette commande dans ton terminal :

```bash
ollama pull gemma3:270m
ğŸ§  Utilisation
Lance le modÃ¨le avec la commande suivante :

bash
Copier le code
ollama run gemma3:270m
Tu peux ensuite discuter directement avec le modÃ¨le dans ton terminal ou lâ€™intÃ©grer Ã  ton application (par exemple via une API ou un script Python).

ğŸ§© Exemple dâ€™utilisation dans un script Python
python
Copier le code
import subprocess

prompt = "Explique le concept de l'apprentissage supervisÃ© en IA."
result = subprocess.run(["ollama", "run", "gemma3:270m"], input=prompt.encode(), capture_output=True)
print(result.stdout.decode())
ğŸ“š Ressources utiles
ğŸ“˜ Documentation dâ€™Ollama : https://github.com/ollama/ollama

ğŸ§© BibliothÃ¨que Gemma 3 (270M) : https://ollama.com/library/gemma3:270m

